{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use the foolbox as the metric that we're minimizing for over hyperspace and see what kind of intersection we get between the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperspace import create_hyperspace\n",
    "from ray import tune\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from skopt import Optimizer\n",
    "import ray\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import foolbox as fb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Tuning with Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_tf_objective(config):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(config['dropout']),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=config['learning_rate'])\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    res = model.fit(x_train, y_train, epochs=config['epochs'], batch_size=config['batch_size'])\n",
    "    res_test = model.evaluate(x_test, y_test)\n",
    "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
    "    images, labels = fb.utils.samples(fmodel, dataset='mnist', batchsize=config['batch_size'])\n",
    "    clean_accuracy = fb.utils.accuracy(fmodel, images, labels)\n",
    "    attack = fb.attacks.GaussianBlurAttack()\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "    # res test[0] reports the loss from the evaluation, res_test[1] reports the accuracy\n",
    "    tune.report(robust_acc = robust_accuracy)\n",
    "    return robust_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages/hyperspace/space/skopt/space.py:173: UserWarning: Each hyperspace contains a single value.\n",
      "  warnings.warn(\"Each hyperspace contains a single value.\")\n"
     ]
    }
   ],
   "source": [
    "### Defining the hyperspace\n",
    "hyperparameters = [(0.00001, 0.1),  # learning_rate\n",
    "                   (0.2, 0.9),  # dropout\n",
    "                   (10, 100),  # epochs \n",
    "                   (10, 1000)]  # batch size\n",
    "space = create_hyperspace(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [mnist_tf_objective_9aef99ec, mnist_tf_objective_9af01d2c, mnist_tf_objective_9af078bc, mnist_tf_objective_9af0d38e, mnist_tf_objective_9af12df2, mnist_tf_objective_9af18694, mnist_tf_objective_9af1dd9c, mnist_tf_objective_9af23a80, mnist_tf_objective_9af293fe, mnist_tf_objective_9af2ec5a, mnist_tf_objective_9af344c0, mnist_tf_objective_9af39bd2, mnist_tf_objective_9af3fc80, mnist_tf_objective_9af45c8e, mnist_tf_objective_9af4b88c, mnist_tf_objective_9af50ce2, mnist_tf_objective_9af56246, mnist_tf_objective_9af5c538, mnist_tf_objective_9af61b0a, mnist_tf_objective_9af6776c])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-222616bb6b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               metric='robust_acc', mode='max')\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# not using a gpu because running on local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_tf_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_algo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"~/Documents/resiliency/gaussianblur_tf_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [mnist_tf_objective_9aef99ec, mnist_tf_objective_9af01d2c, mnist_tf_objective_9af078bc, mnist_tf_objective_9af0d38e, mnist_tf_objective_9af12df2, mnist_tf_objective_9af18694, mnist_tf_objective_9af1dd9c, mnist_tf_objective_9af23a80, mnist_tf_objective_9af293fe, mnist_tf_objective_9af2ec5a, mnist_tf_objective_9af344c0, mnist_tf_objective_9af39bd2, mnist_tf_objective_9af3fc80, mnist_tf_objective_9af45c8e, mnist_tf_objective_9af4b88c, mnist_tf_objective_9af50ce2, mnist_tf_objective_9af56246, mnist_tf_objective_9af5c538, mnist_tf_objective_9af61b0a, mnist_tf_objective_9af6776c])"
     ]
    }
   ],
   "source": [
    "%%capture tf_run_output\n",
    "\n",
    "### for each space in hyperspace, we want to search the space using ray tune\n",
    "results = []\n",
    "for section in tqdm(space):\n",
    "    # create a skopt gp minimize object\n",
    "    optimizer = Optimizer(section)\n",
    "    search_algo = SkOptSearch(optimizer, ['learning_rate', 'dropout', 'epochs', 'batch_size'],\n",
    "                              metric='robust_acc', mode='max')\n",
    "    # not using a gpu because running on local\n",
    "    analysis = tune.run(mnist_tf_objective, search_alg=search_algo, num_samples=20, local_dir=\"~/Documents/resiliency/gaussianblur_tf_1\")\n",
    "    results.append(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
