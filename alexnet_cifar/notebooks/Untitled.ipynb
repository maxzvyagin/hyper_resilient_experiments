{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet\n",
      "  Downloading mxnet-1.7.0.post1-py3-none-macosx_10_13_x86_64.whl (30.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.4 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages (from mxnet) (2.24.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages (from mxnet) (1.18.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/mzvyagin/miniconda3/envs/resiliency/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.7.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From the mxnet mnist tutorial\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import optimizer\n",
    "from mxnet import autograd as ag\n",
    "\n",
    "def mx_objective(config):\n",
    "    # Fixing the random seed\n",
    "    # mx.random.seed(42)\n",
    "    mnist = mx.test_utils.get_mnist()\n",
    "    train_data = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], config['batch_size'])\n",
    "    val_data = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], config['batch_size'])\n",
    "\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.Dense(128, activation='relu'))\n",
    "        net.add(nn.Dense(64, activation='relu'))\n",
    "        net.add(nn.Dense(10))\n",
    "\n",
    "    gpus = mx.test_utils.list_gpus()\n",
    "    ctx = [mx.gpu()] if gpus else [mx.cpu(0), mx.cpu(1)]\n",
    "    net.initialize(mx.init.Uniform(scale=1), ctx=ctx)\n",
    "    optim = optimizer.Adam(learning_rate=config['learning_rate'])\n",
    "    trainer = gluon.Trainer(net.collect_params(), optim)\n",
    "\n",
    "    epoch = config['epochs']\n",
    "    # Use Accuracy as the evaluation metric.\n",
    "    metric = mx.metric.Accuracy()\n",
    "    softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    for i in range(epoch):\n",
    "    # Reset the train data iterator.\n",
    "        train_data.reset()\n",
    "        # Loop over the train data iterator.\n",
    "        for batch in train_data:\n",
    "        # Splits train data into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        # Splits train labels into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = []\n",
    "        # Inside training scope\n",
    "        with ag.record():\n",
    "            for x, y in zip(data, label):\n",
    "                z = net(x)\n",
    "                # Computes softmax cross entropy loss.\n",
    "                loss = softmax_cross_entropy_loss(z, y)\n",
    "                # Backpropagate the error for one iteration.\n",
    "                loss.backward()\n",
    "                outputs.append(z)\n",
    "            # Updates internal evaluation\n",
    "            metric.update(label, outputs)\n",
    "            # Make one step of parameter update. Trainer needs to know the\n",
    "            # batch size of data to normalize the gradient by 1/batch_size.\n",
    "            trainer.step(batch.data[0].shape[0])\n",
    "        # Gets the evaluation result.\n",
    "        name, acc = metric.get()\n",
    "        # Reset evaluation result to initial state.\n",
    "        metric.reset()\n",
    "        print('training acc at epoch %d: %s=%f' % (i, name, acc))\n",
    "\n",
    "    # Use Accuracy as the evaluation metric.\n",
    "    metric = mx.metric.Accuracy()\n",
    "    # Reset the validation data iterator.\n",
    "    val_data.reset()\n",
    "    # Loop over the validation data iterator.\n",
    "    for batch in val_data:\n",
    "    # Splits validation data into multiple slices along batch_axis\n",
    "    # and copy each slice into a context.\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "    # Splits validation label into multiple slices along batch_axis\n",
    "    # and copy each slice into a context.\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = []\n",
    "        for x in data:\n",
    "            outputs.append(net(x))\n",
    "        # Updates internal evaluation\n",
    "        metric.update(label, outputs)\n",
    "    print('validation acc: %s=%f' % metric.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'learning_rate':.001, 'dropout':0.5, 'batch_size':64, 'epochs':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc at epoch 0: accuracy=0.125000\n",
      "training acc at epoch 1: accuracy=0.125000\n",
      "training acc at epoch 2: accuracy=0.109375\n",
      "training acc at epoch 3: accuracy=0.125000\n",
      "training acc at epoch 4: accuracy=0.140625\n",
      "training acc at epoch 5: accuracy=0.140625\n",
      "training acc at epoch 6: accuracy=0.156250\n",
      "training acc at epoch 7: accuracy=0.171875\n",
      "training acc at epoch 8: accuracy=0.187500\n",
      "training acc at epoch 9: accuracy=0.203125\n",
      "training acc at epoch 10: accuracy=0.218750\n",
      "training acc at epoch 11: accuracy=0.250000\n",
      "training acc at epoch 12: accuracy=0.250000\n",
      "training acc at epoch 13: accuracy=0.281250\n",
      "training acc at epoch 14: accuracy=0.312500\n",
      "training acc at epoch 15: accuracy=0.281250\n",
      "training acc at epoch 16: accuracy=0.281250\n",
      "training acc at epoch 17: accuracy=0.343750\n",
      "training acc at epoch 18: accuracy=0.343750\n",
      "training acc at epoch 19: accuracy=0.390625\n",
      "training acc at epoch 20: accuracy=0.421875\n",
      "training acc at epoch 21: accuracy=0.437500\n",
      "training acc at epoch 22: accuracy=0.453125\n",
      "training acc at epoch 23: accuracy=0.468750\n",
      "training acc at epoch 24: accuracy=0.515625\n",
      "training acc at epoch 25: accuracy=0.531250\n",
      "training acc at epoch 26: accuracy=0.578125\n",
      "training acc at epoch 27: accuracy=0.562500\n",
      "training acc at epoch 28: accuracy=0.562500\n",
      "training acc at epoch 29: accuracy=0.593750\n",
      "training acc at epoch 30: accuracy=0.640625\n",
      "training acc at epoch 31: accuracy=0.671875\n",
      "training acc at epoch 32: accuracy=0.671875\n",
      "training acc at epoch 33: accuracy=0.656250\n",
      "training acc at epoch 34: accuracy=0.671875\n",
      "training acc at epoch 35: accuracy=0.687500\n",
      "training acc at epoch 36: accuracy=0.718750\n",
      "training acc at epoch 37: accuracy=0.750000\n",
      "training acc at epoch 38: accuracy=0.765625\n",
      "training acc at epoch 39: accuracy=0.812500\n",
      "training acc at epoch 40: accuracy=0.843750\n",
      "training acc at epoch 41: accuracy=0.859375\n",
      "training acc at epoch 42: accuracy=0.890625\n",
      "training acc at epoch 43: accuracy=0.906250\n",
      "training acc at epoch 44: accuracy=0.906250\n",
      "training acc at epoch 45: accuracy=0.906250\n",
      "training acc at epoch 46: accuracy=0.906250\n",
      "training acc at epoch 47: accuracy=0.937500\n",
      "training acc at epoch 48: accuracy=0.937500\n",
      "training acc at epoch 49: accuracy=0.937500\n",
      "validation acc: accuracy=0.232285\n"
     ]
    }
   ],
   "source": [
    "mx_objective(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
